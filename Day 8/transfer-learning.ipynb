{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from keras.layers import Input, Lambda, Dense, Flatten\nfrom keras.models import Model\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.vgg16 import preprocess_input\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nimport numpy as np\nfrom glob import glob\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-07-08T07:31:29.585254Z","iopub.execute_input":"2022-07-08T07:31:29.585892Z","iopub.status.idle":"2022-07-08T07:31:29.596064Z","shell.execute_reply.started":"2022-07-08T07:31:29.585839Z","shell.execute_reply":"2022-07-08T07:31:29.594853Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"base_path = '../input/face-expression-recognition-dataset/images/'","metadata":{"execution":{"iopub.status.busy":"2022-07-08T07:31:29.598260Z","iopub.execute_input":"2022-07-08T07:31:29.599001Z","iopub.status.idle":"2022-07-08T07:31:29.612056Z","shell.execute_reply.started":"2022-07-08T07:31:29.598950Z","shell.execute_reply":"2022-07-08T07:31:29.610736Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"IMAGE_SIZE=[56,56]","metadata":{"execution":{"iopub.status.busy":"2022-07-08T07:31:29.614038Z","iopub.execute_input":"2022-07-08T07:31:29.614748Z","iopub.status.idle":"2022-07-08T07:31:29.625982Z","shell.execute_reply.started":"2022-07-08T07:31:29.614695Z","shell.execute_reply":"2022-07-08T07:31:29.624621Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# add preprocessing layer to the front of VGG\nvgg = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n\n# don't train existing weights\nfor layer in vgg.layers:\n  layer.trainable = False","metadata":{"execution":{"iopub.status.busy":"2022-07-08T07:31:29.630233Z","iopub.execute_input":"2022-07-08T07:31:29.630756Z","iopub.status.idle":"2022-07-08T07:31:30.197582Z","shell.execute_reply.started":"2022-07-08T07:31:29.630628Z","shell.execute_reply":"2022-07-08T07:31:30.196328Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"nb_classes = 7\n# our layers - you can add more if you want\nx = Flatten()(vgg.output)\n# x = Dense(1000, activation='relu')(x)\nprediction = Dense(nb_classes, activation='softmax')(x)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T07:31:30.199199Z","iopub.execute_input":"2022-07-08T07:31:30.200139Z","iopub.status.idle":"2022-07-08T07:31:30.225602Z","shell.execute_reply.started":"2022-07-08T07:31:30.200083Z","shell.execute_reply":"2022-07-08T07:31:30.224362Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# create a model object\nmodel = Model(inputs=vgg.input, outputs=prediction)\n\n# view the structure of the model\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T07:31:30.228649Z","iopub.execute_input":"2022-07-08T07:31:30.229399Z","iopub.status.idle":"2022-07-08T07:31:30.248465Z","shell.execute_reply.started":"2022-07-08T07:31:30.229348Z","shell.execute_reply":"2022-07-08T07:31:30.247052Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# tell the model what cost and optimization method to use\nmodel.compile(\n  loss='categorical_crossentropy',\n  optimizer='adam',\n  metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T07:31:30.250597Z","iopub.execute_input":"2022-07-08T07:31:30.251128Z","iopub.status.idle":"2022-07-08T07:31:30.266063Z","shell.execute_reply.started":"2022-07-08T07:31:30.251085Z","shell.execute_reply":"2022-07-08T07:31:30.265037Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\n\nbatch_size = 128\nbase_path = \"../input/face-expression-recognition-dataset/images/\"\n\n\ntrain_datagen = ImageDataGenerator(rescale = 1.0/255.0,\n                                  width_shift_range = 0.1,\n                                   height_shift_range = 0.1,\n                                   rotation_range = 20,\n                                   horizontal_flip = True)\n\nvalidation_datagen = ImageDataGenerator(rescale= 1.0/255)\n\ntrain_generator = train_datagen.flow_from_directory(base_path + \"train\",\n                                                    target_size=(56,56),\n                                                    batch_size=batch_size,\n                                                    class_mode='categorical',\n                                                    shuffle=True)\n\nvalidation_generator = validation_datagen.flow_from_directory(base_path + \"validation\",\n                                                    target_size=(56,56),\n                                                    batch_size=batch_size,\n                                                    class_mode='categorical',\n                                                    shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T07:31:30.267457Z","iopub.execute_input":"2022-07-08T07:31:30.268454Z","iopub.status.idle":"2022-07-08T07:31:36.442806Z","shell.execute_reply.started":"2022-07-08T07:31:30.268402Z","shell.execute_reply":"2022-07-08T07:31:36.441555Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# fit the model\nr = model.fit_generator(\n  train_generator,\n  validation_data=validation_generator,\n  epochs=5,\n  steps_per_epoch=train_generator.n//train_generator.batch_size,\n  validation_steps=validation_generator.n//validation_generator.batch_size\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T07:34:16.685792Z","iopub.execute_input":"2022-07-08T07:34:16.686280Z","iopub.status.idle":"2022-07-08T08:20:24.405722Z","shell.execute_reply.started":"2022-07-08T07:34:16.686239Z","shell.execute_reply":"2022-07-08T08:20:24.404510Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# loss\nplt.plot(r.history['loss'], label='train loss')\nplt.plot(r.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\nplt.savefig('LossVal_loss')","metadata":{"execution":{"iopub.status.busy":"2022-07-08T08:42:12.178405Z","iopub.execute_input":"2022-07-08T08:42:12.178833Z","iopub.status.idle":"2022-07-08T08:42:12.412401Z","shell.execute_reply.started":"2022-07-08T08:42:12.178788Z","shell.execute_reply":"2022-07-08T08:42:12.410429Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# accuracies\nplt.plot(r.history['accuracy'], label='train acc')\nplt.plot(r.history['val_accuracy'], label='val acc')\nplt.legend()\nplt.show()\nplt.savefig('AccVal_acc')","metadata":{"execution":{"iopub.status.busy":"2022-07-08T08:42:18.150322Z","iopub.execute_input":"2022-07-08T08:42:18.151063Z","iopub.status.idle":"2022-07-08T08:42:18.360670Z","shell.execute_reply.started":"2022-07-08T08:42:18.151019Z","shell.execute_reply":"2022-07-08T08:42:18.359745Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}